# Neural Networks from Scratch

This repository contains neural network implementations written from scratch in Python and numpy.

## Features
- Activation functions: ReLU, Sigmoid, Tanh, Elu, Leaky_ReLu, Softmax
- Dense, RBF, and rough networks
- Custom loss functions and weight initialization
- Live and offline visualizations
- Preprocessing scripts for data preparation
- Jupyter notebook demonstrating model performance

## Installation
To run this project, install the required dependencies:
```bash
pip install -r requirements.txt
